{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "def create_data_generator(images, labels, batch_size=16):\n",
        "    num_samples = len(images)\n",
        "    while True:\n",
        "        indices = np.random.permutation(num_samples)\n",
        "        for start_idx in range(0, num_samples, batch_size):\n",
        "            end_idx = min(start_idx + batch_size, num_samples)\n",
        "            batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "            batch_images = images[batch_indices]\n",
        "            batch_images = np.stack((batch_images,) * 3, axis=-1)\n",
        "            batch_images = tf.image.resize(batch_images, (96, 96))\n",
        "            batch_images = batch_images / 255.0\n",
        "\n",
        "            batch_labels = to_categorical(labels[batch_indices], 10)\n",
        "            yield batch_images, batch_labels\n",
        "\n",
        "def build_model(input_shape=(96, 96, 3)):\n",
        "    base_model = MobileNetV2(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=input_shape,\n",
        "        pooling='avg'\n",
        "    )\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=input_shape),\n",
        "        layers.RandomRotation(0.1),\n",
        "        base_model,\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "def evaluate_batch(model, images, labels, batch_size=16):\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for i in range(0, len(images), batch_size):\n",
        "        batch_images = images[i:i + batch_size]\n",
        "        batch_labels = labels[i:i + batch_size]\n",
        "\n",
        "        batch_images = np.stack((batch_images,) * 3, axis=-1)\n",
        "        batch_images = tf.image.resize(batch_images, (96, 96))\n",
        "        batch_images = batch_images / 255.0\n",
        "\n",
        "        batch_preds = model.predict(batch_images, verbose=0)\n",
        "        batch_preds = np.argmax(batch_preds, axis=1)\n",
        "\n",
        "        predictions.extend(batch_preds)\n",
        "        true_labels.extend(batch_labels)\n",
        "\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "\n",
        "    precision = precision_score(true_labels, predictions, average='weighted')\n",
        "    recall = recall_score(true_labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    return precision, recall, accuracy\n",
        "\n",
        "def main():\n",
        "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "    train_gen = create_data_generator(train_images, train_labels)\n",
        "    test_gen = create_data_generator(test_images, test_labels)\n",
        "\n",
        "    model = build_model()\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=2, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(factor=0.2, patience=1, min_lr=1e-6)\n",
        "    ]\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        steps_per_epoch=len(train_images) // 16,\n",
        "        epochs=10,\n",
        "        validation_data=test_gen,\n",
        "        validation_steps=len(test_images) // 16,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    precision, recall, accuracy = evaluate_batch(model, test_images, test_labels)\n",
        "\n",
        "    print(f\"\\nTest Metrics:\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    model.save_weights('fashion_mnist_memory_efficient.weights.h5')\n",
        "\n",
        "    return model, history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, history = main()"
      ],
      "metadata": {
        "id": "O2FoH8Eolzla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "352b88f9-5574-4599-e477-bc411476620e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 127ms/step - accuracy: 0.7068 - loss: 0.8471 - val_accuracy: 0.8425 - val_loss: 0.4342 - learning_rate: 0.0010\n",
            "\n",
            "Evaluating model...\n",
            "\n",
            "Test Metrics:\n",
            "Precision: 0.8462\n",
            "Recall: 0.8425\n",
            "Accuracy: 0.8425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    try:\n",
        "        for device in physical_devices:\n",
        "            tf.config.experimental.set_memory_growth(device, True)\n",
        "        print(\"GPU memory growth enabled\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error configuring GPU: {e}\")\n",
        "else:\n",
        "    print(\"No GPU devices found\")\n",
        "\n",
        "tf.config.optimizer.set_jit(True)\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoQI17iK1TMo",
        "outputId": "6efbcf4a-bcf7-4c76-dc4e-558881601203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU memory growth enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(images, labels, batch_size=32):\n",
        "    \"\"\"Create optimized tf.data.Dataset for GPU\"\"\"\n",
        "\n",
        "    images = tf.cast(images, tf.float32)\n",
        "\n",
        "    def preprocess(image, label):\n",
        "\n",
        "        image = tf.stack([image, image, image], axis=-1)\n",
        "        image = tf.image.resize(image, (96, 96))\n",
        "        image = image / 255.0\n",
        "        return image, tf.one_hot(label, 10)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "    dataset = dataset.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(5000)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "voEG69KfIE5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(input_shape=(96, 96, 3)):\n",
        "    with tf.device('/GPU:0'):\n",
        "        base_model = MobileNetV2(\n",
        "            weights='imagenet',\n",
        "            include_top=False,\n",
        "            input_shape=input_shape,\n",
        "            pooling='avg'\n",
        "        )\n",
        "        base_model.trainable = False\n",
        "\n",
        "        model = models.Sequential([\n",
        "            layers.Input(shape=input_shape),\n",
        "            layers.RandomRotation(0.1),\n",
        "            base_model,\n",
        "            layers.Dense(64, activation='relu'),\n",
        "            layers.Dropout(0.5),\n",
        "            layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "LwQd-8n5IMxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(model, optimizer, loss_fn, images, labels):\n",
        "    \"\"\"Custom training step optimized for GPU\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_fn(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss, predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "sHEv08jQITKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataset):\n",
        "    \"\"\"Evaluate model using GPU-optimized batches\"\"\"\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    for batch_images, batch_labels in dataset:\n",
        "        batch_preds = model(batch_images, training=False)\n",
        "        predictions.extend(tf.argmax(batch_preds, axis=1).numpy())\n",
        "        true_labels.extend(tf.argmax(batch_labels, axis=1).numpy())\n",
        "\n",
        "    precision = precision_score(true_labels, predictions, average='weighted')\n",
        "    recall = recall_score(true_labels, predictions, average='weighted')\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "\n",
        "    return precision, recall, accuracy\n",
        "\n",
        "def main():\n",
        "       (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "    batch_size = 64\n",
        "    train_dataset = create_dataset(train_images, train_labels, batch_size)\n",
        "    test_dataset = create_dataset(test_images, test_labels, batch_size)\n",
        "\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    with strategy.scope():\n",
        "        model = build_model()\n",
        "        model.compile(\n",
        "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=2,\n",
        "            min_lr=1e-6,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    print(\"\\nTraining model on GPU...\")\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        epochs=10,\n",
        "        validation_data=test_dataset,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    precision, recall, accuracy = evaluate_model(model, test_dataset)\n",
        "\n",
        "    print(f\"\\nTest Metrics:\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    model.save_weights('fashion_mnist_gpu.weights.h5')\n",
        "\n",
        "    return model, history\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model, history = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqeyBrxkIYWr",
        "outputId": "6e140e8a-2b48-4607-a731-a5c1b43c5d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "\n",
            "Training model on GPU...\n",
            "Epoch 1/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 38ms/step - accuracy: 0.6729 - loss: 0.9641 - val_accuracy: 0.8462 - val_loss: 0.4195 - learning_rate: 0.0010\n",
            "Epoch 2/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 24ms/step - accuracy: 0.8115 - loss: 0.5339 - val_accuracy: 0.8506 - val_loss: 0.4092 - learning_rate: 0.0010\n",
            "Epoch 3/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.8249 - loss: 0.4954 - val_accuracy: 0.8625 - val_loss: 0.3754 - learning_rate: 0.0010\n",
            "Epoch 4/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.8340 - loss: 0.4702 - val_accuracy: 0.8650 - val_loss: 0.3646 - learning_rate: 0.0010\n",
            "Epoch 5/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.8372 - loss: 0.4581 - val_accuracy: 0.8698 - val_loss: 0.3581 - learning_rate: 0.0010\n",
            "Epoch 6/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8421 - loss: 0.4449 - val_accuracy: 0.8679 - val_loss: 0.3582 - learning_rate: 0.0010\n",
            "Epoch 7/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.8459 - loss: 0.4321 - val_accuracy: 0.8713 - val_loss: 0.3559 - learning_rate: 0.0010\n",
            "Epoch 8/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.8456 - loss: 0.4329 - val_accuracy: 0.8731 - val_loss: 0.3546 - learning_rate: 0.0010\n",
            "Epoch 9/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.8489 - loss: 0.4210 - val_accuracy: 0.8702 - val_loss: 0.3539 - learning_rate: 0.0010\n",
            "Epoch 10/10\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.8522 - loss: 0.4196 - val_accuracy: 0.8759 - val_loss: 0.3428 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\n",
            "Evaluating model...\n",
            "\n",
            "Test Metrics:\n",
            "Precision: 0.8750\n",
            "Recall: 0.8759\n",
            "Accuracy: 0.8759\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x8FrexmqMD7g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}